# Neural-Symbolic Integration

While the interest in the symbolic aspects of AI from the mainstream (deep learning) community is quite new, there has actually been a long stream of research focusing on the very topic within a rather small community called Neural-Symbolic Integration (NSI) for learning and reasoning.
NSI has traditionally focused on emulating logic reasoning within neural networks, providing various perspectives into the correspondence between symbolic and sub-symbolic representations and computing. Historically, the community targeted mostly analysis of the correspondence and theoretical model expressiveness, rather than practical learning applications (which is probably why they have been marginalized by the mainstream research).
 However, given the aforementioned recent evolution of the neural/deep learning concept, the NSI field is now gaining more momentum than ever.
What is Neural-Symbolic Integration?
For almost a decade now, deep learning has been the moving force behind most of the progress, success, and hype surrounding the AI landscape. It has taken over the field so rapidly that many people commonly confuse the domains as being equivalent now.
[Artificial Intelligence ~ Machine Learning ~ Deep Learning]
And while the current success and adoption of deep learning largely overshadowed the preceding techniques, these still have some interesting capabilities to offer. In this article, we will look into some of the original symbolic AI principles and how they can be combined with deep learning to leverage the benefits of both of these, seemingly unrelated (or even contradictory), approaches to learning and AI.

# Dynamic Neural Computation

A new stream of neural architectures based on dynamic computational graphs became popular in modern deep learning to tackle structured data in the (non-propositional) form of various sequences, sets, and trees. Most recently, an extension to arbitrary (irregular) graphs then became extremely popular as Graph Neural Networks (GNNs).
These dynamic models finally enable to skip the preprocessing step of turning the relational representations, such as interpretations of a relational logic program, into the fixed-size vector (tensor) format. They do so by effectively reflecting the variations in the input data structures into variations in the structure of the neural model itself, constrained by some shared parameterization (symmetry) scheme reflecting the respective model prior.
And while the particular dynamic deep learning models introduced so far, such as the GNNs, are still just somewhat specific graph-propagation heuristics rather than universal (logic) reasoners, the paradigm of dynamic neural computation finally opens door to properly reflect relational logic reasoning in neural networks, in that classic spirit of the propositional NSI.

# Differentiable Programming
Driven heavily by the empirical success, DL then largely moved away from the original biological brain-inspired models of perceptual intelligence to “whatever works in practice” kind of engineering approach. In essence, the concept evolved into a very generic methodology of using gradient descent to optimize parameters of almost arbitrary nested functions, for which many like to rebrand the field yet again as differentiable programming. This view then made even more space for all sorts of new algorithms, tricks, and tweaks that have been introduced under various catchy names for the underlying functional blocks (still consisting mostly of various combinations of basic linear algebra operations).
But with this evolution, we have also started seeing renewed interest from the deep learning community in the structured, program-like, symbolic representations, albeit in a perhaps unintended manner. Indeed, the modern neural architectures are no longer about stacking more and more fully-connected layers over bigger and bigger datasets, but an incremental amount of prior knowledge in some form of structural bias is being incorporated into the differentiable programs in order to reach to the more complex tasks requiring higher levels of abstraction.
Exactly how much of this prior knowledge to include in the models has then been a subject of many heated debates between researchers in AI.
One of the most successful neural network architectures have been the Convolutional Neural Networks (CNNs)⁴ (tracing back to 1982’s Neocognitron). The distinguishing features introduced in CNNs were the use of shared weights and the idea of pooling.
The shared weights induced by application of convolutional filters here introduce equivariance w.r.t. the respective transformation of the filter, while incorporating the aggregation function on top via pooling extends it further into this transformation invariance. This technique has since proved extremely useful in various tasks involving translation (shift) symmetries.

# The Rise of Deep Learning
The concept of neural networks (as they were called before the deep learning “rebranding”) has actually been around, with various ups and downs, for a few decades already. It dates all the way back to 1943 and the introduction of the first computational neuron. Stacking these on top of each other into layers then became quite popular in the 1980s and ’90s already. However, at that time they were still mostly losing the competition against the more established, and better theoretically substantiated, learning models like SVMs.
The true resurgence of neural networks then started by their rapid empirical success in increasing accuracy on speech recognition tasks in 2010, launching what is now mostly recognized as the modern deep learning era. Shortly afterward, neural networks started to demonstrate the same success in computer vision, too.
Facing the undeniable effectiveness of neural networks on these standard benchmarks for machine perception, researchers slowly (and sometimes reluctantly) started abandoning their advanced feature extraction pipelines designed for the SVMs to adopt the new practice of neural architecture crafting instead.
With this paradigm shift, many variants of the neural networks from the ’80s and ’90s have been rediscovered or newly introduced. Benefiting from the substantial increase in the parallel processing power of modern GPUs, and the ever-increasing amount of available data, deep learning has been steadily paving its way to completely dominate the (perceptual) ML.
